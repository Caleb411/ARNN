{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.optim as optim\n",
    "\n",
    "from typing import *\n",
    "from pathlib import Path\n",
    "from enum import IntEnum\n",
    "class Dim(IntEnum):\n",
    "    batch = 0\n",
    "    seq = 1\n",
    "    feature = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 參數配置\n",
    "csv_path = '../data/nanrui.csv'\n",
    "dim_per_time = 4\n",
    "time_col_count = 2\n",
    "target_dim_index = 0\n",
    "hidden_size = 256\n",
    "\n",
    "train_len = 17434\n",
    "val_len = 5811\n",
    "test_len = 5811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MogLSTM(nn.Module):\n",
    "    def __init__(self, input_sz: int, hidden_sz: int, mog_iterations: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_sz\n",
    "        self.hidden_size = hidden_sz\n",
    "        self.mog_iterations = mog_iterations\n",
    "        #Define/initialize all tensors   \n",
    "        self.Wih = Parameter(torch.Tensor(input_sz, hidden_sz * 4))\n",
    "        self.Whh = Parameter(torch.Tensor(hidden_sz, hidden_sz * 4))\n",
    "        self.bih = Parameter(torch.Tensor(hidden_sz * 4))\n",
    "        self.bhh = Parameter(torch.Tensor(hidden_sz * 4))\n",
    "        #Mogrifiers\n",
    "        self.Q = Parameter(torch.Tensor(hidden_sz,input_sz))\n",
    "        self.R = Parameter(torch.Tensor(input_sz,hidden_sz))\n",
    "\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else:\n",
    "                nn.init.zeros_(p.data)\n",
    "\n",
    "    def mogrify(self,xt,ht):\n",
    "        for i in range(1,self.mog_iterations+1):\n",
    "            if (i % 2 == 0):\n",
    "                ht = (2*torch.sigmoid(xt @ self.R)) * ht\n",
    "            else:\n",
    "                xt = (2*torch.sigmoid(ht @ self.Q)) * xt\n",
    "        return xt, ht\n",
    "\n",
    "    #Define forward pass through all LSTM cells across all timesteps.\n",
    "    #By using PyTorch functions, we get backpropagation for free.\n",
    "    def forward(self, x: torch.Tensor, \n",
    "                init_states: Optional[Tuple[torch.Tensor, torch.Tensor]]=None\n",
    "               ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n",
    "        batch_sz, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        #ht and Ct start as the previous states and end as the output states in each loop below\n",
    "        if init_states is None:\n",
    "            ht = torch.zeros((batch_sz,self.hidden_size)).to(x.device)\n",
    "            Ct = torch.zeros((batch_sz,self.hidden_size)).to(x.device)\n",
    "        else:\n",
    "            ht, Ct = init_states\n",
    "        for t in range(seq_sz): # iterate over the time steps\n",
    "            xt = x[:, t, :]\n",
    "            xt, ht = self.mogrify(xt,ht) #mogrification\n",
    "            gates = (xt @ self.Wih + self.bih) + (ht @ self.Whh + self.bhh)\n",
    "            ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
    "\n",
    "            ### The LSTM Cell!\n",
    "            ft = torch.sigmoid(forgetgate)\n",
    "            it = torch.sigmoid(ingate)\n",
    "            Ct_candidate = torch.tanh(cellgate)\n",
    "            ot = torch.sigmoid(outgate)\n",
    "            #outputs\n",
    "            Ct = (ft * Ct) + (it * Ct_candidate)\n",
    "            ht = ot * torch.tanh(Ct)\n",
    "\n",
    "        return ht, Ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity testing\n",
    "#note that our hidden_sz is also our defined output size for each LSTM cell.\n",
    "batch_sz, seq_len, feat_sz, hidden_sz = 4, 12, 1, 10\n",
    "arr = torch.randn(batch_sz, seq_len, feat_sz)\n",
    "lstm = MogLSTM(feat_sz, hidden_sz,5)\n",
    "hn, cn = lstm(arr)\n",
    "hn.shape #shape should be batch_sz x hidden_sz = 4x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, encoder, hidden_layer_size=hidden_size, output_size=1):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        \n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.encoder(input_seq)\n",
    "        predictions = self.linear(lstm_out)\n",
    "        return predictions.squeeze(1)\n",
    "\n",
    "model = LSTM(MogLSTM(dim_per_time,hidden_size,5))\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据读取\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "data = np.array(df)\n",
    "data = np.array(data[:, time_col_count:], dtype='float')  # 数据删除时间列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(data[:train_len])\n",
    "all_data_normalized = scaler.transform(data)\n",
    "print(all_data_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据生成器函数\n",
    "def generator(data, lookback, delay, min_index, max_index, shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows), lookback // step, data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][target_dim_index]\n",
    "        yield samples, targets, [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 5\n",
    "step = 1\n",
    "delay = 0\n",
    "batch_size = 128\n",
    "train_gen = generator(all_data_normalized,\n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=0,\n",
    "                      max_index=train_len,\n",
    "                      shuffle=True,\n",
    "                      step=step,\n",
    "                      batch_size=batch_size)\n",
    "\n",
    "# 准备数据\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "howmanybatch = (train_len-lookback)//batch_size  # 需要多少个batch\n",
    "for train_one in train_gen:\n",
    "    X.append(train_one[0])\n",
    "    y.append(train_one[1])\n",
    "    howmanybatch = howmanybatch - 1\n",
    "    if howmanybatch == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(X).shape)\n",
    "print(np.array(y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(X)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(torch.FloatTensor(X[i]))\n",
    "\n",
    "        single_loss = loss_function(y_pred, torch.FloatTensor(y[i]))\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'epoch: {epoch:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {epoch:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = generator(all_data_normalized,\n",
    "                     lookback=lookback,\n",
    "                     delay=delay,\n",
    "                     min_index=train_len+val_len,\n",
    "                     max_index=None,\n",
    "                     step=step,\n",
    "                     batch_size=batch_size)\n",
    "\n",
    "# 准备数据\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "howmanybatch = (test_len - lookback) // batch_size  # 需要预测多少个batch\n",
    "for test_one in test_gen:\n",
    "    X.append(test_one[0])\n",
    "    y.append(test_one[1])\n",
    "    howmanybatch = howmanybatch - 1\n",
    "    if howmanybatch == 0:\n",
    "        break\n",
    "\n",
    "test_X = np.vstack(X)\n",
    "test_y = np.hstack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predict_y = model(torch.FloatTensor(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = scaler.inverse_transform(np.repeat(test_y.reshape(-1,1), dim_per_time, axis=1))[:,target_dim_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = scaler.inverse_transform(np.repeat(predict_y.detach().numpy().reshape(-1,1), dim_per_time, axis=1))[:,target_dim_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 误差评估\n",
    "print('mae : ' + str(mean_absolute_error(test_y, predict_y)))\n",
    "print('rmse : ' + str(sqrt(mean_squared_error(test_y, predict_y))))\n",
    "print('r2 : ' + str(r2_score(test_y,predict_y)))\n",
    "\n",
    "# 预测结果部分展现\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(test_y, label='Actual')\n",
    "plt.plot(predict_y, label='MogLSTM')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Temperature')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
